<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="NiuLiangtao">
        <link rel="canonical" href="https://1007530194.github.io/Diary/书籍/机器学习实战/02.k-近邻算法/">
        <link rel="shortcut icon" href="../../../img/favicon.ico">
        <title>2.k-近邻算法 - Blog of NiuLiangtao</title>
        <link href="../../../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../../../css/font-awesome-4.5.0.css" rel="stylesheet">
        <link href="../../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="../../../css/highlight.css">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

        <script src="../../../js/jquery-1.10.2.min.js"></script>
        <script src="../../../js/bootstrap-3.0.3.min.js"></script>
        <script src="../../../js/highlight.pack.js"></script> 
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="../../../ToDo/">Blog of NiuLiangtao</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                    <li >
                        <a href="../../../ToDo/">Home</a>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Home <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../../AboutMe/">About</a>
</li>
                            
<li >
    <a href="../../..">Home</a>
</li>
                            
<li >
    <a href="../../../Nothing/">Nothing</a>
</li>
                            
<li >
    <a href="../../../ToDo/">要做的</a>
</li>
                        </ul>
                    </li>
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">书籍 <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../">Home</a>
</li>
                            
  <li class="dropdown-submenu">
    <a href="#">机器学习实战</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../00naive-bayes-discuss/">naive-bayes-discuss</a>
</li>
            
<li >
    <a href="../01.机器学习基础/">1.机器学习基础</a>
</li>
            
<li class="active">
    <a href="./">2.k-近邻算法</a>
</li>
            
<li >
    <a href="../03.决策树/">03.决策树</a>
</li>
            
<li >
    <a href="../04.朴素贝叶斯/">04.朴素贝叶斯</a>
</li>
            
<li >
    <a href="../05.Logistic回归/">05.Logistic回归</a>
</li>
            
<li >
    <a href="../06.0.支持向量机/">06.0.支持向量机</a>
</li>
            
<li >
    <a href="../06.1.支持向量机的几个通俗理解/">06.1.支持向量机的几个通俗理解</a>
</li>
            
<li >
    <a href="../07.集成方法-随机森林和AdaBoost/">07.集成方法 随机森林和AdaBoost</a>
</li>
            
<li >
    <a href="../08.预测数值型数据-回归/">08.预测数值型数据 回归</a>
</li>
            
<li >
    <a href="../09.树回归/">09.树回归</a>
</li>
            
<li >
    <a href="../10.k-means聚类/">10.k means聚类</a>
</li>
            
<li >
    <a href="../11.使用Apriori算法进行关联分析/">11.使用Apriori算法进行关联分析</a>
</li>
            
<li >
    <a href="../12.使用FP-growth算法来高效发现频繁项集/">12.使用FP growth算法来高效发现频繁项集</a>
</li>
            
<li >
    <a href="../13.利用PCA来简化数据/">13.利用PCA来简化数据</a>
</li>
            
<li >
    <a href="../14.利用SVD简化数据/">14.利用SVD简化数据</a>
</li>
            
<li >
    <a href="../15.大数据与MapReduce/">15.大数据与MapReduce</a>
</li>
            
<li >
    <a href="../16.推荐系统/">16.推荐系统</a>
</li>
    </ul>
  </li>
                            
  <li class="dropdown-submenu">
    <a href="#">深度学习</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../深度学习/DeepLearning/">DeepLearning</a>
</li>
    </ul>
  </li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">学习 <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../../学习/">Home</a>
</li>
                            
  <li class="dropdown-submenu">
    <a href="#">tensorflow</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../学习/tensorflow/如何选择优化器 optimizer/">如何选择优化器 optimizer</a>
</li>
    </ul>
  </li>
                            
  <li class="dropdown-submenu">
    <a href="#">深度学习</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../学习/深度学习/主成分分析-2/">主成分分析 2</a>
</li>
            
<li >
    <a href="../../../学习/深度学习/主成分分析/">主成分分析</a>
</li>
            
<li >
    <a href="../../../学习/深度学习/最小二乘法/">最小二乘法</a>
</li>
            
<li >
    <a href="../../../学习/深度学习/矩阵分解/">矩阵分解</a>
</li>
            
<li >
    <a href="../../../学习/深度学习/矩阵求导/">矩阵求导</a>
</li>
    </ul>
  </li>
                            
  <li class="dropdown-submenu">
    <a href="#">转载</a>
    <ul class="dropdown-menu">
            
  <li class="dropdown-submenu">
    <a href="#">cs231n-ch</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-assignment2_google_cloud/">Ch assignment2 google cloud</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-aws-tutorial/">Ch aws tutorial</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-classification/">Ch classification</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-convnet-tips/">Ch convnet tips</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-convolutional-networks/">Ch convolutional networks</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-google_cloud_tutorial/">Ch google cloud tutorial</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-ipython-tutorial/">Ch ipython tutorial</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-linear-classify/">Ch linear classify</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-neural-networks-1/">Ch neural networks 1</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-neural-networks-2/">Ch neural networks 2</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-neural-networks-3/">Ch neural networks 3</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-neural-networks-case-study/">Ch neural networks case study</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-optimization-1/">Ch optimization 1</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-optimization-2/">Ch optimization 2</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-overview/">Ch overview</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-poster/">Ch poster</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-python-numpy-tutorial/">Ch python numpy tutorial</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-Readme/">ch Readme</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-transfer-learning/">Ch transfer learning</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-understanding-cnn/">Ch understanding cnn</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/terminal-tutorial/">Terminal tutorial</a>
</li>
    </ul>
  </li>
            
  <li class="dropdown-submenu">
    <a href="#">cs231n-en</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-assignment2_google_cloud/">En assignment2 google cloud</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-aws-tutorial/">En aws tutorial</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-classification/">En classification</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-convnet-tips/">En convnet tips</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-convolutional-networks/">En convolutional networks</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-google_cloud_tutorial/">En google cloud tutorial</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-ipython-tutorial/">En ipython tutorial</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-linear-classify/">En linear classify</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-neural-networks-1/">En neural networks 1</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-neural-networks-2/">En neural networks 2</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-neural-networks-3/">En neural networks 3</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-neural-networks-case-study/">En neural networks case study</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-optimization-1/">En optimization 1</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-optimization-2/">En optimization 2</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-overview/">En overview</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-poster/">En poster</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-python-numpy-tutorial/">En python numpy tutorial</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-Readme/">en Readme</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-terminal-tutorial/">En terminal tutorial</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-transfer-learning/">En transfer learning</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-understanding-cnn/">En understanding cnn</a>
</li>
    </ul>
  </li>
            
  <li class="dropdown-submenu">
    <a href="#">example</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../学习/转载/example/a-web-crawer-with-a-asyncio-coroutines-1/">A web crawer with a asyncio coroutines 1</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/a-web-crawer-with-a-asyncio-coroutines-2/">A web crawer with a asyncio coroutines 2</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/bias-variance/">Bias variance</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/bitcoin-explained-1/">Bitcoin explained 1</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/dive-into-gradient-decent/">Dive into gradient decent</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/ethereum-ultimate-guide/">Ethereum ultimate guide</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/fork-exec-source/">Fork exec source</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/latex语法/">Latex语法</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/latex语法1/">Latex语法1</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/nosql-in-python/">Nosql in python</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/perceptron/">Perceptron</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/quick-latex/">Quick latex</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/tendermint/">Tendermint</a>
</li>
    </ul>
  </li>
            
  <li class="dropdown-submenu">
    <a href="#">example2</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../学习/转载/example2/arrays-similar/">Arrays similar</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/baidu-ife-1/">Baidu ife 1</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/create-my-blog-with-jekyll/">Create my blog with jekyll</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/front-end-tools/">Front end tools</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/git-clone-not-master-branch/">Git clone not master branch</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/History-API/">History API</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/how-to-use-babel/">How to use babel</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/how-to-write-a-count-down/">How to write a count down</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/JavaScript-closure/">JavaScript closure</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/JavaScript-function/">JavaScript function</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/JavaScript-good-parts-note1/">JavaScript good parts note1</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/JavaScript-good-parts-note2/">JavaScript good parts note2</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/JavaScript-good-parts-note3/">JavaScript good parts note3</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/JavaScript-Net/">JavaScript Net</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/JavaScript-Object-Oriented/">JavaScript Object Oriented</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/JavaScript-this/">JavaScript this</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/jekyll-theme-version-2.0/">Jekyll theme version 2.0</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/js-create-file-and-download/">Js create file and download</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/low-IE-click-empty-block-bug/">low IE click empty block bug</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/regular-expression-group/">Regular expression group</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/scope/">Scope</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/shuffle-algorithm/">Shuffle algorithm</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/sublimeLinter/">sublimeLinter</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/Syncing-a-fork/">Syncing a fork</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/teach-girlfriend-html-css/">Teach girlfriend html css</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/web-app/">Web app</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/weinre/">Weinre</a>
</li>
    </ul>
  </li>
    </ul>
  </li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">工具 <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../../工具/About/">About</a>
</li>
                            
<li >
    <a href="../../../工具/Cheatsheet/">Cheatsheet</a>
</li>
                            
<li >
    <a href="../../../工具/">Home</a>
</li>
                            
<li >
    <a href="../../../工具/shell显示时间/">Shell显示时间</a>
</li>
                            
  <li class="dropdown-submenu">
    <a href="#">常用工具</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../工具/常用工具/10分钟上手Latex/">10分钟上手Latex</a>
</li>
            
<li >
    <a href="../../../工具/常用工具/10分钟上手Pandas/">10分钟上手Pandas</a>
</li>
            
<li >
    <a href="../../../工具/常用工具/10分钟上手Python/">10分钟上手Python</a>
</li>
    </ul>
  </li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">文章 <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../../文章/">Home</a>
</li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">日常 <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../../日常/">Home</a>
</li>
                            
  <li class="dropdown-submenu">
    <a href="#">test</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../日常/test/testtest/">Testtest</a>
</li>
    </ul>
  </li>
                        </ul>
                    </li>
                </ul>

            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> Search
                    </a>
                </li>
                    <li >
                        <a rel="next" href="../01.机器学习基础/">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../03.决策树/">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/1007530194/Diary">1007530194/Diary</a>
                    </li>
            </ul>
        </div>
    </div>
</div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#2_k-">第2章 k-近邻算法</a></li>
            <li><a href="#knn">KNN 概述</a></li>
            <li><a href="#knn_1">KNN 场景</a></li>
            <li><a href="#knn_2">KNN 原理</a></li>
            <li><a href="#knn_3">KNN 项目案例</a></li>
            <li><a href="#knn_4">KNN 小结</a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<h1 id="2_k-">第2章 k-近邻算法<a class="headerlink" href="#2_k-" title="Permanent link">&para;</a></h1>
<p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script></p>
<h2 id="knn">KNN 概述<a class="headerlink" href="#knn" title="Permanent link">&para;</a></h2>
<p><code>k-近邻（kNN, k-NearestNeighbor）算法是一种基本分类与回归方法，我们这里只讨论分类问题中的 k-近邻算法。</code></p>
<p><strong>一句话总结：近朱者赤近墨者黑！</strong> </p>
<p><code>k 近邻算法的输入为实例的特征向量，对应于特征空间的点；输出为实例的类别，可以取多类。k 近邻算法假设给定一个训练数据集，其中的实例类别已定。分类时，对新的实例，根据其 k 个最近邻的训练实例的类别，通过多数表决等方式进行预测。因此，k近邻算法不具有显式的学习过程。</code></p>
<p><code>k 近邻算法实际上利用训练数据集对特征向量空间进行划分，并作为其分类的“模型”。 k值的选择、距离度量以及分类决策规则是k近邻算法的三个基本要素。</code></p>
<h2 id="knn_1">KNN 场景<a class="headerlink" href="#knn_1" title="Permanent link">&para;</a></h2>
<p>电影可以按照题材分类，那么如何区分 <code>动作片</code> 和 <code>爱情片</code> 呢？<br/>
1. 动作片：打斗次数更多
2. 爱情片：亲吻次数更多</p>
<p>基于电影中的亲吻、打斗出现的次数，使用 k-近邻算法构造程序，就可以自动划分电影的题材类型。</p>
<p><img alt="电影视频案例" src="../resources/2.KNN/knn-1-movie.png" title="电影视频案例" /></p>
<div class="codehilite"><pre><span></span>现在根据上面我们得到的样本集中所有电影与未知电影的距离，按照距离递增排序，可以找到 k 个距离最近的电影。
假定 k=3，则三个最靠近的电影依次是， He&#39;s Not Really into Dudes 、 Beautiful Woman 和 California Man。
knn 算法按照距离最近的三部电影的类型，决定未知电影的类型，而这三部电影全是爱情片，因此我们判定未知电影是爱情片。
</pre></div>

<h2 id="knn_2">KNN 原理<a class="headerlink" href="#knn_2" title="Permanent link">&para;</a></h2>
<blockquote>
<p>KNN 工作原理</p>
</blockquote>
<ol>
<li>假设有一个带有标签的样本数据集（训练样本集），其中包含每条数据与所属分类的对应关系。</li>
<li>输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较。<ol>
<li>计算新数据与样本数据集中每条数据的距离。</li>
<li>对求得的所有距离进行排序（从小到大，越小表示越相似）。</li>
<li>取前 k （k 一般小于等于 20 ）个样本数据对应的分类标签。</li>
</ol>
</li>
<li>求 k 个数据中出现次数最多的分类标签作为新数据的分类。</li>
</ol>
<blockquote>
<p>KNN 通俗理解</p>
</blockquote>
<p>给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的 k 个实例，这 k 个实例的多数属于某个类，就把该输入实例分为这个类。</p>
<blockquote>
<p>KNN 开发流程</p>
</blockquote>
<div class="codehilite"><pre><span></span>收集数据：任何方法
准备数据：距离计算所需要的数值，最好是结构化的数据格式
分析数据：任何方法
训练算法：此步骤不适用于 k-近邻算法
测试算法：计算错误率
使用算法：输入样本数据和结构化的输出结果，然后运行 k-近邻算法判断输入数据分类属于哪个分类，最后对计算出的分类执行后续处理
</pre></div>

<blockquote>
<p>KNN 算法特点</p>
</blockquote>
<div class="codehilite"><pre><span></span>优点：精度高、对异常值不敏感、无数据输入假定
缺点：计算复杂度高、空间复杂度高
适用数据范围：数值型和标称型
</pre></div>

<h2 id="knn_3">KNN 项目案例<a class="headerlink" href="#knn_3" title="Permanent link">&para;</a></h2>
<h3 id="1">项目案例1: 优化约会网站的配对效果<a class="headerlink" href="#1" title="Permanent link">&para;</a></h3>
<p><a href="https://github.com/apachecn/MachineLearning/blob/python-2.7/src/python/2.KNN/kNN.py">完整代码地址</a>: <a href="https://github.com/apachecn/MachineLearning/blob/master/src/python/2.KNN/kNN.py">https://github.com/apachecn/MachineLearning/blob/master/src/python/2.KNN/kNN.py</a></p>
<h4 id="_1">项目概述<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h4>
<p>海伦使用约会网站寻找约会对象。经过一段时间之后，她发现曾交往过三种类型的人:
* 不喜欢的人
* 魅力一般的人
* 极具魅力的人</p>
<p>她希望：
1. 工作日与魅力一般的人约会
2. 周末与极具魅力的人约会
3. 不喜欢的人则直接排除掉</p>
<p>现在她收集到了一些约会网站未曾记录的数据信息，这更有助于匹配对象的归类。</p>
<h4 id="_2">开发流程<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span>收集数据：提供文本文件
准备数据：使用 Python 解析文本文件
分析数据：使用 Matplotlib 画二维散点图
训练算法：此步骤不适用于 k-近邻算法
测试算法：使用海伦提供的部分数据作为测试样本。
        测试样本和非测试样本的区别在于：
            测试样本是已经完成分类的数据，如果预测分类与实际类别不同，则标记为一个错误。
使用算法：产生简单的命令行程序，然后海伦可以输入一些特征数据以判断对方是否为自己喜欢的类型。
</pre></div>

<blockquote>
<p>收集数据：提供文本文件</p>
</blockquote>
<p>海伦把这些约会对象的数据存放在文本文件 <a href="https://github.com/apachecn/MachineLearning/blob/python-2.7/input/2.KNN/datingTestSet2.txt">datingTestSet2.txt</a> 中，总共有 1000 行。海伦约会的对象主要包含以下 3 种特征：</p>
<ul>
<li>每年获得的飞行常客里程数</li>
<li>玩视频游戏所耗时间百分比</li>
<li>每周消费的冰淇淋公升数</li>
</ul>
<p>文本文件数据格式如下：
<div class="codehilite"><pre><span></span>40920   8.326976    0.953952    3
14488   7.153469    1.673904    2
26052   1.441871    0.805124    1
75136   13.147394   0.428964    1
38344   1.669788    0.134296    1
</pre></div></p>
<blockquote>
<p>准备数据：使用 Python 解析文本文件</p>
</blockquote>
<p>将文本记录转换为 NumPy 的解析程序</p>
<p>```python
def file2matrix(filename):
    """
    Desc:
        导入训练数据
    parameters:
        filename: 数据文件路径
    return: 
        数据矩阵 returnMat 和对应的类别 classLabelVector
    """
    fr = open(filename)
    # 获得文件中的数据行的行数
    numberOfLines = len(fr.readlines())
    # 生成对应的空矩阵
    # 例如：zeros(2，3)就是生成一个 2*3的矩阵，各个位置上全是 0 
    returnMat = zeros((numberOfLines, 3))  # prepare matrix to return
    classLabelVector = []  # prepare labels return
    fr = open(filename)
    index = 0
    for line in fr.readlines():
        # str.strip([chars]) --返回移除字符串头尾指定的字符生成的新字符串
        line = line.strip()
        # 以 '\t' 切割字符串
        listFromLine = line.split('\t')
        # 每列的属性数据
        returnMat[index, :] = listFromLine[0:3]
        # 每列的类别数据，就是 label 标签数据
        classLabelVector.append(int(listFromLine[-1]))
        index += 1
    # 返回数据矩阵returnMat和对应的类别classLabelVector
    return returnMat, classLabelVector
<div class="codehilite"><pre><span></span>&gt; 分析数据：使用 Matplotlib 画二维散点图

```python
import matplotlib
import matplotlib.pyplot as plt
fig = plt.figure()
ax = fig.add_subplot(111)
ax.scatter(datingDataMat[:, 0], datingDataMat[:, 1], 15.0*array(datingLabels), 15.0*array(datingLabels))
plt.show()
</pre></div></p>
<p>下图中采用矩阵的第一和第二列属性得到很好的展示效果，清晰地标识了三个不同的样本分类区域，具有不同爱好的人其类别区域也不同。</p>
<p><img alt="Matplotlib 散点图" src="../resources/2.KNN/knn_matplotlib_2.png" /></p>
<ul>
<li>归一化数据 （归一化是一个让权重变为统一的过程，更多细节请参考： <a href="https://www.zhihu.com/question/19951858">https://www.zhihu.com/question/19951858</a> ）</li>
</ul>
<table>
<thead>
<tr>
<th>序号</th>
<th align="center">玩视频游戏所耗时间百分比</th>
<th align="right">每年获得的飞行常客里程数</th>
<th align="right">每周消费的冰淇淋公升数</th>
<th align="right">样本分类</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td align="center">0.8</td>
<td align="right">400</td>
<td align="right">0.5</td>
<td align="right">1</td>
</tr>
<tr>
<td>2</td>
<td align="center">12</td>
<td align="right">134 000</td>
<td align="right">0.9</td>
<td align="right">3</td>
</tr>
<tr>
<td>3</td>
<td align="center">0</td>
<td align="right">20 000</td>
<td align="right">1.1</td>
<td align="right">2</td>
</tr>
<tr>
<td>4</td>
<td align="center">67</td>
<td align="right">32 000</td>
<td align="right">0.1</td>
<td align="right">2</td>
</tr>
</tbody>
</table>
<p>样本3和样本4的距离：
<span><span class="MathJax_Preview"><span><span class="MathJax_Preview">\sqrt{(0-67)^2 + (20000-32000)^2 + (1.1-0.1)^2 }</span><script type="math/tex">\sqrt{(0-67)^2 + (20000-32000)^2 + (1.1-0.1)^2 }</script></span></span><script type="math/tex"><span><span class="MathJax_Preview">\sqrt{(0-67)^2 + (20000-32000)^2 + (1.1-0.1)^2 }</span><script type="math/tex">\sqrt{(0-67)^2 + (20000-32000)^2 + (1.1-0.1)^2 }</script></span></script></span></p>
<p>归一化特征值，消除特征之间量级不同导致的影响</p>
<p><strong>归一化定义：</strong> 我是这样认为的，归一化就是要把你需要处理的数据经过处理后（通过某种算法）限制在你需要的一定范围内。首先归一化是为了后面数据处理的方便，其次是保正程序运行时收敛加快。 方法有如下：</p>
<p>1) 线性函数转换，表达式如下：　　</p>
<div class="codehilite"><pre><span></span>y=(x-MinValue)/(MaxValue-MinValue)

说明：x、y分别为转换前、后的值，MaxValue、MinValue分别为样本的最大值和最小值。
</pre></div>


<p>2) 对数函数转换，表达式如下：　　</p>
<div class="codehilite"><pre><span></span>y=log10(x)

说明：以10为底的对数函数转换。

如图：

![对数函数图像](resources/2.KNN/knn_1.png)
</pre></div>


<p>3) 反余切函数转换，表达式如下：</p>
<div class="codehilite"><pre><span></span>y=arctan(x)*2/PI

如图：

![反余切函数图像](resources/2.KNN/arctan_arccot.gif)
</pre></div>


<p>4) 式(1)将输入值换算为[-1,1]区间的值，在输出层用式(2)换算回初始值，其中和分别表示训练样本集中负荷的最大值和最小值。　</p>
<p>在统计学中，归一化的具体作用是归纳统一样本的统计分布性。归一化在0-1之间是统计的概率分布，归一化在-1--+1之间是统计的坐标分布。</p>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">autoNorm</span><span class="p">(</span><span class="n">dataSet</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Desc:</span>
<span class="sd">        归一化特征值，消除特征之间量级不同导致的影响</span>
<span class="sd">    parameter:</span>
<span class="sd">        dataSet: 数据集</span>
<span class="sd">    return:</span>
<span class="sd">        归一化后的数据集 normDataSet. ranges和minVals即最小值与范围，并没有用到</span>

<span class="sd">    归一化公式：</span>
<span class="sd">        Y = (X-Xmin)/(Xmax-Xmin)</span>
<span class="sd">        其中的 min 和 max 分别是数据集中的最小特征值和最大特征值。该函数可以自动将数字特征值转化为0到1的区间。</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># 计算每种属性的最大值、最小值、范围</span>
    <span class="n">minVals</span> <span class="o">=</span> <span class="n">dataSet</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">maxVals</span> <span class="o">=</span> <span class="n">dataSet</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># 极差</span>
    <span class="n">ranges</span> <span class="o">=</span> <span class="n">maxVals</span> <span class="o">-</span> <span class="n">minVals</span>
    <span class="n">normDataSet</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">dataSet</span><span class="p">))</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">dataSet</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># 生成与最小值之差组成的矩阵</span>
    <span class="n">normDataSet</span> <span class="o">=</span> <span class="n">dataSet</span> <span class="o">-</span> <span class="n">tile</span><span class="p">(</span><span class="n">minVals</span><span class="p">,</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="c1"># 将最小值之差除以范围组成矩阵</span>
    <span class="n">normDataSet</span> <span class="o">=</span> <span class="n">normDataSet</span> <span class="o">/</span> <span class="n">tile</span><span class="p">(</span><span class="n">ranges</span><span class="p">,</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># element wise divide</span>
    <span class="k">return</span> <span class="n">normDataSet</span><span class="p">,</span> <span class="n">ranges</span><span class="p">,</span> <span class="n">minVals</span>
</pre></div>

<blockquote>
<p>训练算法：此步骤不适用于 k-近邻算法</p>
</blockquote>
<p>因为测试数据每一次都要与全量的训练数据进行比较，所以这个过程是没有必要的。</p>
<p>kNN 算法伪代码：</p>
<div class="codehilite"><pre><span></span>对于每一个在数据集中的数据点：
    计算目标的数据点（需要分类的数据点）与该数据点的距离
    将距离排序：从小到大
    选取前K个最短距离
    选取这K个中最多的分类类别
    返回该类别来作为目标数据点的预测值
</pre></div>


<p><code>python
def classify0(inX, dataSet, labels, k):
    dataSetSize = dataSet.shape[0]
    #距离度量 度量公式为欧氏距离
    diffMat = tile(inX, (dataSetSize,1)) – dataSet
    sqDiffMat = diffMat**2
    sqDistances = sqDiffMat.sum(axis=1)
    distances = sqDistances**0.5
    
    #将距离排序：从小到大
    sortedDistIndicies = distances.argsort()
    #选取前K个最短距离， 选取这K个中最多的分类类别
    classCount={}
    for i in range(k)：
        voteIlabel = labels[sortedDistIndicies[i]]
        classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1 
    sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(1), reverse=True)
    return sortedClassCount[0][0]</code></p>
<blockquote>
<p>测试算法：使用海伦提供的部分数据作为测试样本。如果预测分类与实际类别不同，则标记为一个错误。</p>
</blockquote>
<p>kNN 分类器针对约会网站的测试代码</p>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">datingClassTest</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Desc:</span>
<span class="sd">        对约会网站的测试方法</span>
<span class="sd">    parameters:</span>
<span class="sd">        none</span>
<span class="sd">    return:</span>
<span class="sd">        错误数</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># 设置测试数据的的一个比例（训练数据集比例=1-hoRatio）</span>
    <span class="n">hoRatio</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># 测试范围,一部分测试一部分作为样本</span>
    <span class="c1"># 从文件中加载数据</span>
    <span class="n">datingDataMat</span><span class="p">,</span> <span class="n">datingLabels</span> <span class="o">=</span> <span class="n">file2matrix</span><span class="p">(</span><span class="s1">&#39;input/2.KNN/datingTestSet2.txt&#39;</span><span class="p">)</span>  <span class="c1"># load data setfrom file</span>
    <span class="c1"># 归一化数据</span>
    <span class="n">normMat</span><span class="p">,</span> <span class="n">ranges</span><span class="p">,</span> <span class="n">minVals</span> <span class="o">=</span> <span class="n">autoNorm</span><span class="p">(</span><span class="n">datingDataMat</span><span class="p">)</span>
    <span class="c1"># m 表示数据的行数，即矩阵的第一维</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">normMat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># 设置测试的样本数量， numTestVecs:m表示训练样本的数量</span>
    <span class="n">numTestVecs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">m</span> <span class="o">*</span> <span class="n">hoRatio</span><span class="p">)</span>
    <span class="k">print</span> <span class="s1">&#39;numTestVecs=&#39;</span><span class="p">,</span> <span class="n">numTestVecs</span>
    <span class="n">errorCount</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numTestVecs</span><span class="p">):</span>
        <span class="c1"># 对数据测试</span>
        <span class="n">classifierResult</span> <span class="o">=</span> <span class="n">classify0</span><span class="p">(</span><span class="n">normMat</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="n">normMat</span><span class="p">[</span><span class="n">numTestVecs</span><span class="p">:</span><span class="n">m</span><span class="p">,</span> <span class="p">:],</span> <span class="n">datingLabels</span><span class="p">[</span><span class="n">numTestVecs</span><span class="p">:</span><span class="n">m</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span>
        <span class="k">print</span> <span class="s2">&quot;the classifier came back with: </span><span class="si">%d</span><span class="s2">, the real answer is: </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">classifierResult</span><span class="p">,</span> <span class="n">datingLabels</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">classifierResult</span> <span class="o">!=</span> <span class="n">datingLabels</span><span class="p">[</span><span class="n">i</span><span class="p">]):</span> <span class="n">errorCount</span> <span class="o">+=</span> <span class="mf">1.0</span>
    <span class="k">print</span> <span class="s2">&quot;the total error rate is: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">errorCount</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">numTestVecs</span><span class="p">))</span>
    <span class="k">print</span> <span class="n">errorCount</span>
</pre></div>

<blockquote>
<p>使用算法：产生简单的命令行程序，然后海伦可以输入一些特征数据以判断对方是否为自己喜欢的类型。</p>
</blockquote>
<p>约会网站预测函数</p>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">classifyPerson</span><span class="p">():</span>
    <span class="n">resultList</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;not at all&#39;</span><span class="p">,</span> <span class="s1">&#39;in small doses&#39;</span><span class="p">,</span> <span class="s1">&#39;in large doses&#39;</span><span class="p">]</span>
    <span class="n">percentTats</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">raw_input</span><span class="p">(</span><span class="s2">&quot;percentage of time spent playing video games ?&quot;</span><span class="p">))</span>
    <span class="n">ffMiles</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">raw_input</span><span class="p">(</span><span class="s2">&quot;frequent filer miles earned per year?&quot;</span><span class="p">))</span>
    <span class="n">iceCream</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">raw_input</span><span class="p">(</span><span class="s2">&quot;liters of ice cream consumed per year?&quot;</span><span class="p">))</span>
    <span class="n">datingDataMat</span><span class="p">,</span> <span class="n">datingLabels</span> <span class="o">=</span> <span class="n">file2matrix</span><span class="p">(</span><span class="s1">&#39;datingTestSet2.txt&#39;</span><span class="p">)</span>
    <span class="n">normMat</span><span class="p">,</span> <span class="n">ranges</span><span class="p">,</span> <span class="n">minVals</span> <span class="o">=</span> <span class="n">autoNorm</span><span class="p">(</span><span class="n">datingDataMat</span><span class="p">)</span>
    <span class="n">inArr</span> <span class="o">=</span> <span class="n">array</span><span class="p">([</span><span class="n">ffMiles</span><span class="p">,</span> <span class="n">percentTats</span><span class="p">,</span> <span class="n">iceCream</span><span class="p">])</span>
    <span class="n">classifierResult</span> <span class="o">=</span> <span class="n">classify0</span><span class="p">((</span><span class="n">inArr</span><span class="o">-</span><span class="n">minVals</span><span class="p">)</span><span class="o">/</span><span class="n">ranges</span><span class="p">,</span><span class="n">normMat</span><span class="p">,</span><span class="n">datingLabels</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="k">print</span> <span class="s2">&quot;You will probably like this person: &quot;</span><span class="p">,</span> <span class="n">resultList</span><span class="p">[</span><span class="n">classifierResult</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>

<p>实际运行效果如下: </p>
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">classifyPerson</span><span class="p">()</span>
<span class="n">percentage</span> <span class="n">of</span> <span class="n">time</span> <span class="n">spent</span> <span class="n">playing</span> <span class="n">video</span> <span class="n">games</span><span class="err">?</span><span class="mi">10</span>
<span class="n">frequent</span> <span class="n">flier</span> <span class="n">miles</span> <span class="n">earned</span> <span class="n">per</span> <span class="n">year</span><span class="err">?</span><span class="mi">10000</span>
<span class="n">liters</span> <span class="n">of</span> <span class="n">ice</span> <span class="n">cream</span> <span class="n">consumed</span> <span class="n">per</span> <span class="n">year</span><span class="err">?</span><span class="mf">0.5</span>
<span class="n">You</span> <span class="n">will</span> <span class="n">probably</span> <span class="n">like</span> <span class="n">this</span> <span class="n">person</span><span class="p">:</span> <span class="ow">in</span> <span class="n">small</span> <span class="n">doses</span>
</pre></div>

<h3 id="2">项目案例2: 手写数字识别系统<a class="headerlink" href="#2" title="Permanent link">&para;</a></h3>
<p><a href="https://github.com/apachecn/MachineLearning/blob/python-2.7/src/python/2.KNN/kNN.py">完整代码地址</a>: <a href="https://github.com/apachecn/MachineLearning/blob/master/src/python/2.KNN/kNN.py">https://github.com/apachecn/MachineLearning/blob/master/src/python/2.KNN/kNN.py</a></p>
<h4 id="_3">项目概述<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h4>
<p>构造一个能识别数字 0 到 9 的基于 KNN 分类器的手写数字识别系统。</p>
<p>需要识别的数字是存储在文本文件中的具有相同的色彩和大小：宽高是 32 像素 * 32 像素的黑白图像。</p>
<h4 id="_4">开发流程<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span>收集数据：提供文本文件。
准备数据：编写函数 img2vector(), 将图像格式转换为分类器使用的向量格式
分析数据：在 Python 命令提示符中检查数据，确保它符合要求
训练算法：此步骤不适用于 KNN
测试算法：编写函数使用提供的部分数据集作为测试样本，测试样本与非测试样本的
         区别在于测试样本是已经完成分类的数据，如果预测分类与实际类别不同，
         则标记为一个错误
使用算法：本例没有完成此步骤，若你感兴趣可以构建完整的应用程序，从图像中提取
         数字，并完成数字识别，美国的邮件分拣系统就是一个实际运行的类似系统
</pre></div>

<blockquote>
<p>收集数据: 提供文本文件</p>
</blockquote>
<p>目录 <a href="https://github.com/apachecn/MachineLearning/blob/python-2.7/input/2.KNN/trainingDigits">trainingDigits</a> 中包含了大约 2000 个例子，每个例子内容如下图所示，每个数字大约有 200 个样本；目录 <a href="https://github.com/apachecn/MachineLearning/blob/python-2.7/input/2.KNN/testDigits">testDigits</a> 中包含了大约 900 个测试数据。</p>
<p><img alt="手写数字数据集的例子" src="../resources/2.KNN/knn_2_handWriting.png" /></p>
<blockquote>
<p>准备数据: 编写函数 img2vector(), 将图像文本数据转换为分类器使用的向量</p>
</blockquote>
<p>将图像文本数据转换为向量</p>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">img2vector</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="n">returnVect</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">1024</span><span class="p">))</span>
    <span class="n">fr</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">32</span><span class="p">):</span>
        <span class="n">lineStr</span> <span class="o">=</span> <span class="n">fr</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">32</span><span class="p">):</span>
            <span class="n">returnVect</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">32</span><span class="o">*</span><span class="n">i</span><span class="o">+</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">lineStr</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">returnVect</span>
</pre></div>

<blockquote>
<p>分析数据：在 Python 命令提示符中检查数据，确保它符合要求</p>
</blockquote>
<p>在 Python 命令行中输入下列命令测试 img2vector 函数，然后与文本编辑器打开的文件进行比较: </p>
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">testVector</span> <span class="o">=</span> <span class="n">kNN</span><span class="o">.</span><span class="n">img2vector</span><span class="p">(</span><span class="s1">&#39;testDigits/0_13.txt&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">testVector</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">32</span><span class="p">]</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">testVector</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">32</span><span class="p">:</span><span class="mi">64</span><span class="p">]</span>
<span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">])</span>
</pre></div>

<blockquote>
<p>训练算法：此步骤不适用于 KNN</p>
</blockquote>
<p>因为测试数据每一次都要与全量的训练数据进行比较，所以这个过程是没有必要的。</p>
<blockquote>
<p>测试算法：编写函数使用提供的部分数据集作为测试样本，如果预测分类与实际类别不同，则标记为一个错误</p>
</blockquote>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">handwritingClassTest</span><span class="p">():</span>
    <span class="c1"># 1. 导入训练数据</span>
    <span class="n">hwLabels</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">trainingFileList</span> <span class="o">=</span> <span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;input/2.KNN/trainingDigits&#39;</span><span class="p">)</span>  <span class="c1"># load the training set</span>
    <span class="n">m</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainingFileList</span><span class="p">)</span>
    <span class="n">trainingMat</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="mi">1024</span><span class="p">))</span>
    <span class="c1"># hwLabels存储0～9对应的index位置， trainingMat存放的每个位置对应的图片向量</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="n">fileNameStr</span> <span class="o">=</span> <span class="n">trainingFileList</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">fileStr</span> <span class="o">=</span> <span class="n">fileNameStr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># take off .txt</span>
        <span class="n">classNumStr</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">fileStr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">hwLabels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">classNumStr</span><span class="p">)</span>
        <span class="c1"># 将 32*32的矩阵-&gt;1*1024的矩阵</span>
        <span class="n">trainingMat</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">img2vector</span><span class="p">(</span><span class="s1">&#39;input/2.KNN/trainingDigits/</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">fileNameStr</span><span class="p">)</span>

    <span class="c1"># 2. 导入测试数据</span>
    <span class="n">testFileList</span> <span class="o">=</span> <span class="n">listdir</span><span class="p">(</span><span class="s1">&#39;input/2.KNN/testDigits&#39;</span><span class="p">)</span>  <span class="c1"># iterate through the test set</span>
    <span class="n">errorCount</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">mTest</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">testFileList</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mTest</span><span class="p">):</span>
        <span class="n">fileNameStr</span> <span class="o">=</span> <span class="n">testFileList</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">fileStr</span> <span class="o">=</span> <span class="n">fileNameStr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># take off .txt</span>
        <span class="n">classNumStr</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">fileStr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">vectorUnderTest</span> <span class="o">=</span> <span class="n">img2vector</span><span class="p">(</span><span class="s1">&#39;input/2.KNN/testDigits/</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">fileNameStr</span><span class="p">)</span>
        <span class="n">classifierResult</span> <span class="o">=</span> <span class="n">classify0</span><span class="p">(</span><span class="n">vectorUnderTest</span><span class="p">,</span> <span class="n">trainingMat</span><span class="p">,</span> <span class="n">hwLabels</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="k">print</span> <span class="s2">&quot;the classifier came back with: </span><span class="si">%d</span><span class="s2">, the real answer is: </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">classifierResult</span><span class="p">,</span> <span class="n">classNumStr</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">classifierResult</span> <span class="o">!=</span> <span class="n">classNumStr</span><span class="p">):</span> <span class="n">errorCount</span> <span class="o">+=</span> <span class="mf">1.0</span>
    <span class="k">print</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">the total number of errors is: </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">errorCount</span>
    <span class="k">print</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">the total error rate is: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">errorCount</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">mTest</span><span class="p">))</span>
</pre></div>

<blockquote>
<p>使用算法：本例没有完成此步骤，若你感兴趣可以构建完整的应用程序，从图像中提取数字，并完成数字识别，美国的邮件分拣系统就是一个实际运行的类似系统</p>
</blockquote>
<h2 id="knn_4">KNN 小结<a class="headerlink" href="#knn_4" title="Permanent link">&para;</a></h2>
<p>经过上面的介绍我们可以知道， k 近邻算法有 三个基本的要素：</p>
<ul>
<li>
<p>k 值的选择</p>
<ul>
<li>k 值的选择会对 k 近邻算法的结果产生重大的影响。</li>
<li>如果选择较小的 k 值，就相当于用较小的邻域中的训练实例进行预测，“学习”的近似误差（approximation error）会减小，只有与输入实例较近的（相似的）训练实例才会对预测结果起作用。但缺点是“学习”的估计误差（estimation error）会增大，预测结果会对近邻的实例点非常敏感。如果邻近的实例点恰巧是噪声，预测就会出错。换句话说，k 值的减小就意味着整体模型变得复杂，容易发生过拟合。</li>
<li>如果选择较大的 k 值，就相当于用较大的邻域中的训练实例进行预测。其优点是可以减少学习的估计误差。但缺点是学习的近似误差会增大。这时与输入实例较远的（不相似的）训练实例也会对预测起作用，使预测发生错误。 k 值的增大就意味着整体的模型变得简单。</li>
<li>近似误差和估计误差，请看这里：<a href="https://www.zhihu.com/question/60793482">https://www.zhihu.com/question/60793482</a></li>
</ul>
</li>
<li>
<p>距离度量</p>
<ul>
<li>特征空间中两个实例点的距离是两个实例点相似程度的反映。</li>
<li>k 近邻模型的特征空间一般是 n 维实数向量空间 <img alt="向量空间" src="../resources/2.KNN/knn_3.png" /> 。使用的距离是欧氏距离，但也可以是其他距离，如更一般的 <img alt="Lp距离" src="../resources/2.KNN/knn_4.png" /> 距离，或者 Minkowski 距离。</li>
</ul>
</li>
<li>
<p>分类决策规则</p>
<ul>
<li>k 近邻算法中的分类决策规则往往是多数表决，即由输入实例的 k 个邻近的训练实例中的多数类决定输入实例的类。</li>
</ul>
</li>
</ul>
<hr />
<ul>
<li><strong>作者：<a href="http://www.apache.wiki/display/~xuxin">羊三</a> <a href="http://www.apache.wiki/display/~chenyao">小瑶</a></strong></li>
<li><a href="https://github.com/apachecn/MachineLearning">GitHub地址</a>: <a href="https://github.com/apachecn/MachineLearning">https://github.com/apachecn/MachineLearning</a></li>
<li><strong>版权声明：欢迎转载学习 =&gt; 请标注信息来源于 <a href="http://www.apachecn.org/">ApacheCN</a></strong></li>
</ul></div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Copyright &copy; 2016 - 2018 Martin Donath</p>
            <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>var base_url = '../../..';</script>
        <script src="../../../js/base.js"></script>
        <script src="../../../javascripts/extra.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        <script src="../../../search/require.js"></script>
        <script src="../../../search/search.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="Keyboard Shortcuts Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Keyboard Shortcuts</h4>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td><kbd>&larr;</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td><kbd>&rarr;</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>


    </body>
</html>
