<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="NiuLiangtao">
        <link rel="canonical" href="https://1007530194.github.io/Diary/书籍/机器学习实战/10.k-means聚类/">
        <link rel="shortcut icon" href="../../../img/favicon.ico">
        <title>10.k-means聚类 - Blog of NiuLiangtao</title>
        <link href="../../../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../../../css/font-awesome-4.5.0.css" rel="stylesheet">
        <link href="../../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="../../../css/highlight.css">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

        <script src="../../../js/jquery-1.10.2.min.js"></script>
        <script src="../../../js/bootstrap-3.0.3.min.js"></script>
        <script src="../../../js/highlight.pack.js"></script> 
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="../../../ToDo/">Blog of NiuLiangtao</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                    <li >
                        <a href="../../../ToDo/">Home</a>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Home <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../../AboutMe/">About</a>
</li>
                            
<li >
    <a href="../../..">Home</a>
</li>
                            
<li >
    <a href="../../../Nothing/">Nothing</a>
</li>
                            
<li >
    <a href="../../../ToDo/">要做的</a>
</li>
                        </ul>
                    </li>
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">书籍 <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../">Home</a>
</li>
                            
  <li class="dropdown-submenu">
    <a href="#">机器学习实战</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../00naive-bayes-discuss/">naive-bayes-discuss</a>
</li>
            
<li >
    <a href="../01.机器学习基础/">1.机器学习基础</a>
</li>
            
<li >
    <a href="../02.k-近邻算法/">2.k-近邻算法</a>
</li>
            
<li >
    <a href="../03.决策树/">3.决策树</a>
</li>
            
<li >
    <a href="../04.朴素贝叶斯/">4.朴素贝叶斯</a>
</li>
            
<li >
    <a href="../05.Logistic回归/">5.Logistic回归</a>
</li>
            
<li >
    <a href="../06.0.支持向量机/">6.支持向量机</a>
</li>
            
<li >
    <a href="../06.1.支持向量机的几个通俗理解/">6.1.支持向量机的几个通俗理解</a>
</li>
            
<li >
    <a href="../07.集成方法-随机森林和AdaBoost/">7.集成方法-随机森林和AdaBoost</a>
</li>
            
<li >
    <a href="../08.预测数值型数据-回归/">8.预测数值型数据：回归</a>
</li>
            
<li >
    <a href="../09.树回归/">9.树回归</a>
</li>
            
<li class="active">
    <a href="./">10.k-means聚类</a>
</li>
            
<li >
    <a href="../11.使用Apriori算法进行关联分析/">11.使用Apriori算法进行关联分析</a>
</li>
            
<li >
    <a href="../12.使用FP-growth算法来高效发现频繁项集/">12.使用FP growth算法来高效发现频繁项集</a>
</li>
            
<li >
    <a href="../13.利用PCA来简化数据/">13.利用PCA来简化数据</a>
</li>
            
<li >
    <a href="../14.利用SVD简化数据/">14.利用SVD简化数据</a>
</li>
            
<li >
    <a href="../15.大数据与MapReduce/">15.大数据与MapReduce</a>
</li>
            
<li >
    <a href="../16.推荐系统/">16.推荐系统</a>
</li>
    </ul>
  </li>
                            
  <li class="dropdown-submenu">
    <a href="#">深度学习</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../深度学习/DeepLearning/">DeepLearning</a>
</li>
    </ul>
  </li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">学习 <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../../学习/">Home</a>
</li>
                            
  <li class="dropdown-submenu">
    <a href="#">tensorflow</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../学习/tensorflow/如何选择优化器 optimizer/">如何选择优化器 optimizer</a>
</li>
    </ul>
  </li>
                            
  <li class="dropdown-submenu">
    <a href="#">深度学习</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../学习/深度学习/主成分分析-2/">主成分分析 2</a>
</li>
            
<li >
    <a href="../../../学习/深度学习/主成分分析/">主成分分析</a>
</li>
            
<li >
    <a href="../../../学习/深度学习/最小二乘法/">最小二乘法</a>
</li>
            
<li >
    <a href="../../../学习/深度学习/矩阵分解/">矩阵分解</a>
</li>
            
<li >
    <a href="../../../学习/深度学习/矩阵求导/">矩阵求导</a>
</li>
    </ul>
  </li>
                            
  <li class="dropdown-submenu">
    <a href="#">转载</a>
    <ul class="dropdown-menu">
            
  <li class="dropdown-submenu">
    <a href="#">cs231n-ch</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-assignment2_google_cloud/">Ch assignment2 google cloud</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-aws-tutorial/">Ch aws tutorial</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-classification/">Ch classification</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-convnet-tips/">Ch convnet tips</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-convolutional-networks/">Ch convolutional networks</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-google_cloud_tutorial/">Ch google cloud tutorial</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-ipython-tutorial/">Ch ipython tutorial</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-linear-classify/">Ch linear classify</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-neural-networks-1/">Ch neural networks 1</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-neural-networks-2/">Ch neural networks 2</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-neural-networks-3/">Ch neural networks 3</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-neural-networks-case-study/">Ch neural networks case study</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-optimization-1/">Ch optimization 1</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-optimization-2/">Ch optimization 2</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-overview/">Ch overview</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-poster/">Ch poster</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-python-numpy-tutorial/">Ch python numpy tutorial</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-Readme/">ch Readme</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-transfer-learning/">Ch transfer learning</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/ch-understanding-cnn/">Ch understanding cnn</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-ch/terminal-tutorial/">Terminal tutorial</a>
</li>
    </ul>
  </li>
            
  <li class="dropdown-submenu">
    <a href="#">cs231n-en</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-assignment2_google_cloud/">En assignment2 google cloud</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-aws-tutorial/">En aws tutorial</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-classification/">En classification</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-convnet-tips/">En convnet tips</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-convolutional-networks/">En convolutional networks</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-google_cloud_tutorial/">En google cloud tutorial</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-ipython-tutorial/">En ipython tutorial</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-linear-classify/">En linear classify</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-neural-networks-1/">En neural networks 1</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-neural-networks-2/">En neural networks 2</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-neural-networks-3/">En neural networks 3</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-neural-networks-case-study/">En neural networks case study</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-optimization-1/">En optimization 1</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-optimization-2/">En optimization 2</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-overview/">En overview</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-poster/">En poster</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-python-numpy-tutorial/">En python numpy tutorial</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-Readme/">en Readme</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-terminal-tutorial/">En terminal tutorial</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-transfer-learning/">En transfer learning</a>
</li>
            
<li >
    <a href="../../../学习/转载/cs231n-en/en-understanding-cnn/">En understanding cnn</a>
</li>
    </ul>
  </li>
            
  <li class="dropdown-submenu">
    <a href="#">example</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../学习/转载/example/a-web-crawer-with-a-asyncio-coroutines-1/">A web crawer with a asyncio coroutines 1</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/a-web-crawer-with-a-asyncio-coroutines-2/">A web crawer with a asyncio coroutines 2</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/bias-variance/">Bias variance</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/bitcoin-explained-1/">Bitcoin explained 1</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/dive-into-gradient-decent/">Dive into gradient decent</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/ethereum-ultimate-guide/">Ethereum ultimate guide</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/fork-exec-source/">Fork exec source</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/latex语法/">Latex语法</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/latex语法1/">Latex语法1</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/nosql-in-python/">Nosql in python</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/perceptron/">Perceptron</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/quick-latex/">Quick latex</a>
</li>
            
<li >
    <a href="../../../学习/转载/example/tendermint/">Tendermint</a>
</li>
    </ul>
  </li>
            
  <li class="dropdown-submenu">
    <a href="#">example2</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../学习/转载/example2/arrays-similar/">Arrays similar</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/baidu-ife-1/">Baidu ife 1</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/create-my-blog-with-jekyll/">Create my blog with jekyll</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/front-end-tools/">Front end tools</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/git-clone-not-master-branch/">Git clone not master branch</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/History-API/">History API</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/how-to-use-babel/">How to use babel</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/how-to-write-a-count-down/">How to write a count down</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/JavaScript-closure/">JavaScript closure</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/JavaScript-function/">JavaScript function</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/JavaScript-good-parts-note1/">JavaScript good parts note1</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/JavaScript-good-parts-note2/">JavaScript good parts note2</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/JavaScript-good-parts-note3/">JavaScript good parts note3</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/JavaScript-Net/">JavaScript Net</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/JavaScript-Object-Oriented/">JavaScript Object Oriented</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/JavaScript-this/">JavaScript this</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/jekyll-theme-version-2.0/">Jekyll theme version 2.0</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/js-create-file-and-download/">Js create file and download</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/low-IE-click-empty-block-bug/">low IE click empty block bug</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/regular-expression-group/">Regular expression group</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/scope/">Scope</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/shuffle-algorithm/">Shuffle algorithm</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/sublimeLinter/">sublimeLinter</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/Syncing-a-fork/">Syncing a fork</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/teach-girlfriend-html-css/">Teach girlfriend html css</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/web-app/">Web app</a>
</li>
            
<li >
    <a href="../../../学习/转载/example2/weinre/">Weinre</a>
</li>
    </ul>
  </li>
    </ul>
  </li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">工具 <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../../工具/About/">About</a>
</li>
                            
<li >
    <a href="../../../工具/Cheatsheet/">Cheatsheet</a>
</li>
                            
<li >
    <a href="../../../工具/">Home</a>
</li>
                            
<li >
    <a href="../../../工具/shell显示时间/">Shell显示时间</a>
</li>
                            
  <li class="dropdown-submenu">
    <a href="#">常用工具</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../工具/常用工具/10分钟上手Latex/">10分钟上手Latex</a>
</li>
            
<li >
    <a href="../../../工具/常用工具/10分钟上手Pandas/">10分钟上手Pandas</a>
</li>
            
<li >
    <a href="../../../工具/常用工具/10分钟上手Python/">10分钟上手Python</a>
</li>
    </ul>
  </li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">文章 <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../../文章/">Home</a>
</li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">日常 <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../../日常/">Home</a>
</li>
                            
  <li class="dropdown-submenu">
    <a href="#">test</a>
    <ul class="dropdown-menu">
            
<li >
    <a href="../../../日常/test/testtest/">Testtest</a>
</li>
    </ul>
  </li>
                        </ul>
                    </li>
                </ul>

            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> Search
                    </a>
                </li>
                    <li >
                        <a rel="next" href="../09.树回归/">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../11.使用Apriori算法进行关联分析/">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/1007530194/Diary">1007530194/Diary</a>
                    </li>
            </ul>
        </div>
    </div>
</div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#10_k-meansk-">第 10 章 K-Means（K-均值）聚类算法</a></li>
            <li><a href="#k-means">K-Means 算法</a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<h1 id="10_k-meansk-">第 10 章 K-Means（K-均值）聚类算法<a class="headerlink" href="#10_k-meansk-" title="Permanent link">&para;</a></h1>
<h2 id="k-means">K-Means 算法<a class="headerlink" href="#k-means" title="Permanent link">&para;</a></h2>
<p>聚类是一种无监督的学习, 它将相似的对象归到一个簇中, 将不相似对象归到不同簇中.<br />
相似这一概念取决于所选择的相似度计算方法.<br />
K-Means 是发现给定数据集的 K 个簇的聚类算法, 之所以称之为 <code>K-均值</code> 是因为它可以发现 K 个不同的簇, 且每个簇的中心采用簇中所含值的均值计算而成.<br />
簇个数 K 是用户指定的, 每一个簇通过其质心（centroid）, 即簇中所有点的中心来描述.<br />
聚类与分类算法的最大区别在于, 分类的目标类别已知, 而聚类的目标类别是未知的.  </p>
<div class="codehilite"><pre><span></span>优点: 容易实现
缺点:可能收敛到局部最小值, 在大规模数据集上收敛较慢
使用数据类型 : 数值型数据
</pre></div>

<h3 id="k-means_1">K-Means 场景<a class="headerlink" href="#k-means_1" title="Permanent link">&para;</a></h3>
<p>主要用来聚类, 但是类别是未知的.<br />
例如: 对地图上的点进行聚类.</p>
<h3 id="k-means_2">K-Means 术语<a class="headerlink" href="#k-means_2" title="Permanent link">&para;</a></h3>
<ul>
<li>簇: 所有数据点点集合，簇中的对象是相似的。</li>
<li>质心: 簇中所有点的中心（计算所有点的均值而来）.</li>
<li>SSE: Sum of Sqared Error（平方误差和）, SSE 值越小，表示越接近它们的质心. 由于对误差取了平方，因此更加注重那么远离中心的点.</li>
</ul>
<p>有关 <code>簇</code> 和 <code>质心</code> 术语更形象的介绍, 请参考下图:</p>
<p><img alt="K-Means 术语图" src="../resources/10.KMeans/apachecn-k-means-term-1.jpg" /></p>
<h3 id="k-means_3">K-Means 工作流程<a class="headerlink" href="#k-means_3" title="Permanent link">&para;</a></h3>
<ol>
<li>首先, 随机确定 K 个初始点作为质心（不是数据中的点）.</li>
<li>然后将数据集中的每个点分配到一个簇中, 具体来讲, 就是为每个点找到距其最近的质心, 并将其分配该质心所对应的簇. 这一步完成之后, 每个簇的质心更新为该簇所有点的平均值.</li>
</ol>
<p>上述过程的 <code>伪代码</code> 如下:</p>
<ul>
<li>创建 k 个点作为起始质心（通常是随机选择）</li>
<li>当任意一个点的簇分配结果发生改变时<ul>
<li>对数据集中的每个数据点<ul>
<li>对每个质心<ul>
<li>计算质心与数据点之间的距离</li>
</ul>
</li>
<li>将数据点分配到距其最近的簇</li>
</ul>
</li>
<li>对每一个簇, 计算簇中所有点的均值并将均值作为质心</li>
</ul>
</li>
</ul>
<h3 id="k-means_4">K-Means 开发流程<a class="headerlink" href="#k-means_4" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span>收集数据：使用任意方法
准备数据：需要数值型数据类计算距离, 也可以将标称型数据映射为二值型数据再用于距离计算
分析数据：使用任意方法
训练算法：此步骤不适用于 K-Means 算法
测试算法：应用聚类算法、观察结果.可以使用量化的误差指标如误差平方和（后面会介绍）来评价算法的结果.
使用算法：可以用于所希望的任何应用.通常情况下, 簇质心可以代表整个簇的数据来做出决策.
</pre></div>

<h3 id="k-means_5">K-Means 聚类算法函数<a class="headerlink" href="#k-means_5" title="Permanent link">&para;</a></h3>
<h4 id="_1">从文件加载数据集<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><span class="c1"># 从文本中构建矩阵，加载文本文件，然后处理</span>
<span class="k">def</span> <span class="nf">loadDataSet</span><span class="p">(</span><span class="n">fileName</span><span class="p">):</span>    <span class="c1"># 通用函数，用来解析以 tab 键分隔的 floats（浮点数），例如: 1.658985    4.285136</span>
    <span class="n">dataMat</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">fr</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">fileName</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">fr</span><span class="o">.</span><span class="n">readlines</span><span class="p">():</span>
        <span class="n">curLine</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">fltLine</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">float</span><span class="p">,</span><span class="n">curLine</span><span class="p">)</span>    <span class="c1"># 映射所有的元素为 float（浮点数）类型</span>
        <span class="n">dataMat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fltLine</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dataMat</span>
</pre></div>

<h4 id="_2">计算两个向量的欧氏距离<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><span class="c1"># 计算两个向量的欧式距离（可根据场景选择）</span>
<span class="k">def</span> <span class="nf">distEclud</span><span class="p">(</span><span class="n">vecA</span><span class="p">,</span> <span class="n">vecB</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">power</span><span class="p">(</span><span class="n">vecA</span> <span class="o">-</span> <span class="n">vecB</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span> <span class="c1"># la.norm(vecA-vecB)</span>
</pre></div>

<h4 id="k">构建一个包含 K 个随机质心的集合<a class="headerlink" href="#k" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><span class="c1"># 为给定数据集构建一个包含 k 个随机质心的集合。随机质心必须要在整个数据集的边界之内，这可以通过找到数据集每一维的最小和最大值来完成。然后生成 0~1.0 之间的随机数并通过取值范围和最小值，以便确保随机点在数据的边界之内。</span>
<span class="k">def</span> <span class="nf">randCent</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">shape</span><span class="p">(</span><span class="n">dataSet</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># 列的数量</span>
    <span class="n">centroids</span> <span class="o">=</span> <span class="n">mat</span><span class="p">(</span><span class="n">zeros</span><span class="p">((</span><span class="n">k</span><span class="p">,</span><span class="n">n</span><span class="p">)))</span> <span class="c1"># 创建k个质心矩阵</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span> <span class="c1"># 创建随机簇质心，并且在每一维的边界内</span>
        <span class="n">minJ</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">dataSet</span><span class="p">[:,</span><span class="n">j</span><span class="p">])</span>    <span class="c1"># 最小值</span>
        <span class="n">rangeJ</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">dataSet</span><span class="p">[:,</span><span class="n">j</span><span class="p">])</span> <span class="o">-</span> <span class="n">minJ</span><span class="p">)</span>    <span class="c1"># 范围 = 最大值 - 最小值</span>
        <span class="n">centroids</span><span class="p">[:,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">mat</span><span class="p">(</span><span class="n">minJ</span> <span class="o">+</span> <span class="n">rangeJ</span> <span class="o">*</span> <span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>    <span class="c1"># 随机生成</span>
    <span class="k">return</span> <span class="n">centroids</span>
</pre></div>

<h4 id="k-means_6">K-Means 聚类算法<a class="headerlink" href="#k-means_6" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><span class="c1"># k-means 聚类算法</span>
<span class="c1"># 该算法会创建k个质心，然后将每个点分配到最近的质心，再重新计算质心。</span>
<span class="c1"># 这个过程重复数次，直到数据点的簇分配结果不再改变位置。</span>
<span class="c1"># 运行结果（多次运行结果可能会不一样，可以试试，原因为随机质心的影响，但总的结果是对的， 因为数据足够相似，也可能会陷入局部最小值）</span>
<span class="k">def</span> <span class="nf">kMeans</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">distMeas</span><span class="o">=</span><span class="n">distEclud</span><span class="p">,</span> <span class="n">createCent</span><span class="o">=</span><span class="n">randCent</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">shape</span><span class="p">(</span><span class="n">dataSet</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>    <span class="c1"># 行数</span>
    <span class="n">clusterAssment</span> <span class="o">=</span> <span class="n">mat</span><span class="p">(</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>    <span class="c1"># 创建一个与 dataSet 行数一样，但是有两列的矩阵，用来保存簇分配结果</span>
    <span class="n">centroids</span> <span class="o">=</span> <span class="n">createCent</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>    <span class="c1"># 创建质心，随机k个质心</span>
    <span class="n">clusterChanged</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="k">while</span> <span class="n">clusterChanged</span><span class="p">:</span>
        <span class="n">clusterChanged</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>    <span class="c1"># 循环每一个数据点并分配到最近的质心中去</span>
            <span class="n">minDist</span> <span class="o">=</span> <span class="n">inf</span><span class="p">;</span> <span class="n">minIndex</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
                <span class="n">distJI</span> <span class="o">=</span> <span class="n">distMeas</span><span class="p">(</span><span class="n">centroids</span><span class="p">[</span><span class="n">j</span><span class="p">,:],</span><span class="n">dataSet</span><span class="p">[</span><span class="n">i</span><span class="p">,:])</span>    <span class="c1"># 计算数据点到质心的距离</span>
                <span class="k">if</span> <span class="n">distJI</span> <span class="o">&lt;</span> <span class="n">minDist</span><span class="p">:</span>    <span class="c1"># 如果距离比 minDist（最小距离）还小，更新 minDist（最小距离）和最小质心的 index（索引）</span>
                    <span class="n">minDist</span> <span class="o">=</span> <span class="n">distJI</span><span class="p">;</span> <span class="n">minIndex</span> <span class="o">=</span> <span class="n">j</span>
            <span class="k">if</span> <span class="n">clusterAssment</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">minIndex</span><span class="p">:</span>    <span class="c1"># 簇分配结果改变</span>
                <span class="n">clusterChanged</span> <span class="o">=</span> <span class="bp">True</span>    <span class="c1"># 簇改变</span>
                <span class="n">clusterAssment</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">minIndex</span><span class="p">,</span><span class="n">minDist</span><span class="o">**</span><span class="mi">2</span>    <span class="c1"># 更新簇分配结果为最小质心的 index（索引），minDist（最小距离）的平方</span>
        <span class="k">print</span> <span class="n">centroids</span>
        <span class="k">for</span> <span class="n">cent</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span> <span class="c1"># 更新质心</span>
            <span class="n">ptsInClust</span> <span class="o">=</span> <span class="n">dataSet</span><span class="p">[</span><span class="n">nonzero</span><span class="p">(</span><span class="n">clusterAssment</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">A</span><span class="o">==</span><span class="n">cent</span><span class="p">)[</span><span class="mi">0</span><span class="p">]]</span> <span class="c1"># 获取该簇中的所有点</span>
            <span class="n">centroids</span><span class="p">[</span><span class="n">cent</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">ptsInClust</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># 将质心修改为簇中所有点的平均值，mean 就是求平均值的</span>
    <span class="k">return</span> <span class="n">centroids</span><span class="p">,</span> <span class="n">clusterAssment</span>
</pre></div>

<h4 id="_3">测试函数<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h4>
<ol>
<li>测试一下以上的基础函数是否可以如预期运行, 请看: <a href="https://github.com/apachecn/MachineLearning/blob/master/src/python/10.kmeans/kMeans.py">https://github.com/apachecn/MachineLearning/blob/master/src/python/10.kmeans/kMeans.py</a></li>
<li>测试一下 kMeans 函数是否可以如预期运行, 请看: <a href="https://github.com/apachecn/MachineLearning/blob/master/src/python/10.kmeans/kMeans.py">https://github.com/apachecn/MachineLearning/blob/master/src/python/10.kmeans/kMeans.py</a> </li>
</ol>
<p>参考运行结果如下:<br />
<img alt="K-Means 运行结果1" src="../resources/10.KMeans/apachecn-k-means-run-result-1.jpg" /></p>
<blockquote>
<p>在 kMeans 的函数测试中，可能偶尔会陷入局部最小值（局部最优的结果，但不是全局最优的结果）.</p>
</blockquote>
<h3 id="k-means_7">K-Means 聚类算法的缺陷<a class="headerlink" href="#k-means_7" title="Permanent link">&para;</a></h3>
<p>在 kMeans 的函数测试中，可能偶尔会陷入局部最小值（局部最优的结果，但不是全局最优的结果）. <br />
局部最小值的的情况如下:<br />
<img alt="K-Means 局部最小值1" src="../resources/10.KMeans/apachecn-kmeans-partial-best-result-1.jpg" /></p>
<p>所以为了克服 KMeans 算法收敛于局部最小值的问题，有更厉害的大佬提出了另一个称之为二分K-均值（bisecting K-Means）的算法.   </p>
<h3 id="k-means_8">二分 K-Means 聚类算法<a class="headerlink" href="#k-means_8" title="Permanent link">&para;</a></h3>
<p>该算法首先将所有点作为一个簇，然后将该簇一分为二。<br />
之后选择其中一个簇继续进行划分，选择哪一个簇进行划分取决于对其划分时候可以最大程度降低 SSE（平方和误差）的值。<br />
上述基于 SSE 的划分过程不断重复，直到得到用户指定的簇数目为止。  </p>
<h4 id="k-means_9">二分 K-Means 聚类算法伪代码<a class="headerlink" href="#k-means_9" title="Permanent link">&para;</a></h4>
<ul>
<li>将所有点看成一个簇</li>
<li>当簇数目小雨 k 时</li>
<li>对于每一个簇<ul>
<li>计算总误差</li>
<li>在给定的簇上面进行 KMeans 聚类（k=2）</li>
<li>计算将该簇一分为二之后的总误差</li>
</ul>
</li>
<li>选择使得误差最小的那个簇进行划分操作</li>
</ul>
<p>另一种做法是选择 SSE 最大的簇进行划分，直到簇数目达到用户指定的数目位置。
接下来主要介绍该做法。</p>
<h4 id="k-means_10">二分 K-Means 聚类算法代码<a class="headerlink" href="#k-means_10" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><span class="c1"># 二分 KMeans 聚类算法, 基于 kMeans 基础之上的优化，以避免陷入局部最小值</span>
<span class="k">def</span> <span class="nf">biKMeans</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">distMeas</span><span class="o">=</span><span class="n">distEclud</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">shape</span><span class="p">(</span><span class="n">dataSet</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">clusterAssment</span> <span class="o">=</span> <span class="n">mat</span><span class="p">(</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span> <span class="c1"># 保存每个数据点的簇分配结果和平方误差</span>
    <span class="n">centroid0</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># 质心初始化为所有数据点的均值</span>
    <span class="n">centList</span> <span class="o">=</span><span class="p">[</span><span class="n">centroid0</span><span class="p">]</span> <span class="c1"># 初始化只有 1 个质心的 list</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span> <span class="c1"># 计算所有数据点到初始质心的距离平方误差</span>
        <span class="n">clusterAssment</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">distMeas</span><span class="p">(</span><span class="n">mat</span><span class="p">(</span><span class="n">centroid0</span><span class="p">),</span> <span class="n">dataSet</span><span class="p">[</span><span class="n">j</span><span class="p">,:])</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">while</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">centList</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">k</span><span class="p">):</span> <span class="c1"># 当质心数量小于 k 时</span>
        <span class="n">lowestSSE</span> <span class="o">=</span> <span class="n">inf</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">centList</span><span class="p">)):</span> <span class="c1"># 对每一个质心</span>
            <span class="n">ptsInCurrCluster</span> <span class="o">=</span> <span class="n">dataSet</span><span class="p">[</span><span class="n">nonzero</span><span class="p">(</span><span class="n">clusterAssment</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">A</span><span class="o">==</span><span class="n">i</span><span class="p">)[</span><span class="mi">0</span><span class="p">],:]</span> <span class="c1"># 获取当前簇 i 下的所有数据点</span>
            <span class="n">centroidMat</span><span class="p">,</span> <span class="n">splitClustAss</span> <span class="o">=</span> <span class="n">kMeans</span><span class="p">(</span><span class="n">ptsInCurrCluster</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">distMeas</span><span class="p">)</span> <span class="c1"># 将当前簇 i 进行二分 kMeans 处理</span>
            <span class="n">sseSplit</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">splitClustAss</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># 将二分 kMeans 结果中的平方和的距离进行求和</span>
            <span class="n">sseNotSplit</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">clusterAssment</span><span class="p">[</span><span class="n">nonzero</span><span class="p">(</span><span class="n">clusterAssment</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">A</span><span class="o">!=</span><span class="n">i</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># 将未参与二分 kMeans 分配结果中的平方和的距离进行求和</span>
            <span class="k">print</span> <span class="s2">&quot;sseSplit, and notSplit: &quot;</span><span class="p">,</span><span class="n">sseSplit</span><span class="p">,</span><span class="n">sseNotSplit</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">sseSplit</span> <span class="o">+</span> <span class="n">sseNotSplit</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">lowestSSE</span><span class="p">:</span> <span class="c1"># 总的（未拆分和已拆分）误差和越小，越相似，效果越优化，划分的结果更好（注意：这里的理解很重要，不明白的地方可以和我们一起讨论）</span>
                <span class="n">bestCentToSplit</span> <span class="o">=</span> <span class="n">i</span>
                <span class="n">bestNewCents</span> <span class="o">=</span> <span class="n">centroidMat</span>
                <span class="n">bestClustAss</span> <span class="o">=</span> <span class="n">splitClustAss</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">lowestSSE</span> <span class="o">=</span> <span class="n">sseSplit</span> <span class="o">+</span> <span class="n">sseNotSplit</span>
        <span class="c1"># 找出最好的簇分配结果    </span>
        <span class="n">bestClustAss</span><span class="p">[</span><span class="n">nonzero</span><span class="p">(</span><span class="n">bestClustAss</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">A</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">centList</span><span class="p">)</span> <span class="c1"># 调用二分 kMeans 的结果，默认簇是 0,1. 当然也可以改成其它的数字</span>
        <span class="n">bestClustAss</span><span class="p">[</span><span class="n">nonzero</span><span class="p">(</span><span class="n">bestClustAss</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">A</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">bestCentToSplit</span> <span class="c1"># 更新为最佳质心</span>
        <span class="k">print</span> <span class="s1">&#39;the bestCentToSplit is: &#39;</span><span class="p">,</span><span class="n">bestCentToSplit</span>
        <span class="k">print</span> <span class="s1">&#39;the len of bestClustAss is: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">bestClustAss</span><span class="p">)</span>
        <span class="c1"># 更新质心列表</span>
        <span class="n">centList</span><span class="p">[</span><span class="n">bestCentToSplit</span><span class="p">]</span> <span class="o">=</span> <span class="n">bestNewCents</span><span class="p">[</span><span class="mi">0</span><span class="p">,:]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># 更新原质心 list 中的第 i 个质心为使用二分 kMeans 后 bestNewCents 的第一个质心</span>
        <span class="n">centList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bestNewCents</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># 添加 bestNewCents 的第二个质心</span>
        <span class="n">clusterAssment</span><span class="p">[</span><span class="n">nonzero</span><span class="p">(</span><span class="n">clusterAssment</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">A</span> <span class="o">==</span> <span class="n">bestCentToSplit</span><span class="p">)[</span><span class="mi">0</span><span class="p">],:]</span><span class="o">=</span> <span class="n">bestClustAss</span> <span class="c1"># 重新分配最好簇下的数据（质心）以及SSE</span>
    <span class="k">return</span> <span class="n">mat</span><span class="p">(</span><span class="n">centList</span><span class="p">),</span> <span class="n">clusterAssment</span>
</pre></div>

<h4 id="kmeans">测试二分 KMeans 聚类算法<a class="headerlink" href="#kmeans" title="Permanent link">&para;</a></h4>
<ul>
<li>测试一下二分 KMeans 聚类算法，请看: <a href="https://github.com/apachecn/MachineLearning/blob/master/src/python/10.kmeans/kMeans.py">https://github.com/apachecn/MachineLearning/blob/master/src/python/10.kmeans/kMeans.py</a></li>
</ul>
<p>上述函数可以运行多次，聚类会收敛到全局最小值，而原始的 kMeans() 函数偶尔会陷入局部最小值。<br />
运行参考结果如下:<br />
<img alt="二分 K-Means 运行结果1" src="../resources/10.KMeans/apachecn-bikmeans-run-result-1.jpg" /></p>
<ul>
<li><strong>作者：<a href="http://www.apache.wiki/display/~xuxin">那伊抹微笑</a></strong></li>
<li><a href="https://github.com/apachecn/MachineLearning">GitHub地址</a>: <a href="https://github.com/apachecn/MachineLearning">https://github.com/apachecn/MachineLearning</a></li>
<li><strong>版权声明：欢迎转载学习 =&gt; 请标注信息来源于 <a href="http://www.apachecn.org/">ApacheCN</a></strong></li>
</ul></div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Copyright &copy; 2016 - 2018 Martin Donath</p>
            <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>var base_url = '../../..';</script>
        <script src="../../../js/base.js"></script>
        <script src="../../../javascripts/extra.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        <script src="../../../search/require.js"></script>
        <script src="../../../search/search.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="Keyboard Shortcuts Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Keyboard Shortcuts</h4>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td><kbd>&larr;</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td><kbd>&rarr;</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>


    </body>
</html>
