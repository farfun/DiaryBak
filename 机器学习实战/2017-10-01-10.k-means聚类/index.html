<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../../img/favicon.ico">
        <title>10.k-means聚类.md - DataLab</title>
        <link href="../../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../../css/font-awesome-4.5.0.css" rel="stylesheet">
        <link href="../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="../../css/highlight.css">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

        <script src="../../js/jquery-1.10.2.min.js"></script>
        <script src="../../js/bootstrap-3.0.3.min.js"></script>
        <script src="../../js/highlight.pack.js"></script> 
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="../..">DataLab</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Home <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../..">Home</a>
</li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Home <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../About/">About</a>
</li>
                            
<li >
    <a href="../../Cheatsheet/">Cheatsheet</a>
</li>
                            
<li >
    <a href="../../Index/">Index</a>
</li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">常用 <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../常用/2018-02-23-latex语法/">latex语法.md</a>
</li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">常用工具 <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../常用工具/2018-02-24-10分钟上手Pandas/">10分钟上手Pandas.md</a>
</li>
                        </ul>
                    </li>
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">机器学习实战 <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../2017-01-01-1.机器学习基础/">1.机器学习基础.md</a>
</li>
                            
<li >
    <a href="../2017-02-01-2.k-近邻算法/">2.k-近邻算法.md</a>
</li>
                            
<li >
    <a href="../2017-03-01-3.决策树/">3.决策树.md</a>
</li>
                            
<li >
    <a href="../2017-04-01-4.朴素贝叶斯/">4.朴素贝叶斯.md</a>
</li>
                            
<li >
    <a href="../2017-04-02-naive-bayes-discuss/">naive-bayes-discuss.md</a>
</li>
                            
<li >
    <a href="../2017-05-01-5.Logistic回归/">5.Logistic回归.md</a>
</li>
                            
<li >
    <a href="../2017-06-01-6.支持向量机/">6.支持向量机.md</a>
</li>
                            
<li >
    <a href="../2017-06-02-6.1.支持向量机的几个通俗理解/">6.1.支持向量机的几个通俗理解.md</a>
</li>
                            
<li >
    <a href="../2017-07-01-7.集成方法-随机森林和AdaBoost/">7.集成方法-随机森林和AdaBoost.md</a>
</li>
                            
<li >
    <a href="../2017-09-01-9.树回归/">9.树回归.md</a>
</li>
                            
<li class="active">
    <a href="./">10.k-means聚类.md</a>
</li>
                            
<li >
    <a href="../2017-11-01-11.使用Apriori算法进行关联分析/">2017 11 01 11.使用Apriori算法进行关联分析</a>
</li>
                            
<li >
    <a href="../2017-12-01-12.使用FP-growth算法来高效发现频繁项集/">2017 12 01 12.使用FP growth算法来高效发现频繁项集</a>
</li>
                            
<li >
    <a href="../2018-01-01-13.利用PCA来简化数据/">2018 01 01 13.利用PCA来简化数据</a>
</li>
                            
<li >
    <a href="../2018-02-01-14.利用SVD简化数据/">2018 02 01 14.利用SVD简化数据</a>
</li>
                            
<li >
    <a href="../2018-03-01-15.大数据与MapReduce/">2018 03 01 15.大数据与MapReduce</a>
</li>
                            
<li >
    <a href="../2018-04-01-16.推荐系统/">2018 04 01 16.推荐系统</a>
</li>
                            
<li >
    <a href="../预测数值型数据,回归/">预测数值型数据,回归</a>
</li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">深度学习 <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../../深度学习/2018-02-23-10分钟上手Pandas/">2018 02 23 10分钟上手Pandas</a>
</li>
                            
<li >
    <a href="../../深度学习/2018-02-23-主成分分析 (2)/">2018 02 23 主成分分析 (2)</a>
</li>
                            
<li >
    <a href="../../深度学习/2018-02-23-主成分分析/">2018 02 23 主成分分析</a>
</li>
                            
<li >
    <a href="../../深度学习/2018-02-23-最小二乘法/">2018 02 23 最小二乘法</a>
</li>
                            
<li >
    <a href="../../深度学习/2018-02-23-矩阵分解/">2018 02 23 矩阵分解</a>
</li>
                            
<li >
    <a href="../../深度学习/2018-02-23-矩阵求导/">2018 02 23 矩阵求导</a>
</li>
                        </ul>
                    </li>
                </ul>

            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> Search
                    </a>
                </li>
                    <li >
                        <a rel="next" href="../2017-09-01-9.树回归/">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../2017-11-01-11.使用Apriori算法进行关联分析/">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>
            </ul>
        </div>
    </div>
</div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#10-k-meansk-">第 10 章 K-Means（K-均值）聚类算法</a></li>
            <li><a href="#k-means">K-Means 算法</a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<ul>
<li>content
{:toc}</li>
</ul>
<h1 id="10-k-meansk-">第 10 章 K-Means（K-均值）聚类算法</h1>
<h2 id="k-means">K-Means 算法</h2>
<p>聚类是一种无监督的学习, 它将相似的对象归到一个簇中, 将不相似对象归到不同簇中.<br />
相似这一概念取决于所选择的相似度计算方法.<br />
K-Means 是发现给定数据集的 K 个簇的聚类算法, 之所以称之为 <code>K-均值</code> 是因为它可以发现 K 个不同的簇, 且每个簇的中心采用簇中所含值的均值计算而成.<br />
簇个数 K 是用户指定的, 每一个簇通过其质心（centroid）, 即簇中所有点的中心来描述.<br />
聚类与分类算法的最大区别在于, 分类的目标类别已知, 而聚类的目标类别是未知的.  </p>
<div class="highlight"><pre><span></span>优点: 容易实现
缺点:可能收敛到局部最小值, 在大规模数据集上收敛较慢
使用数据类型 : 数值型数据
</pre></div>

<h3 id="k-means_1">K-Means 场景</h3>
<p>主要用来聚类, 但是类别是未知的.<br />
例如: 对地图上的点进行聚类.</p>
<h3 id="k-means_2">K-Means 术语</h3>
<ul>
<li>簇: 所有数据点点集合，簇中的对象是相似的。</li>
<li>质心: 簇中所有点的中心（计算所有点的均值而来）.</li>
<li>SSE: Sum of Sqared Error（平方误差和）, SSE 值越小，表示越接近它们的质心. 由于对误差取了平方，因此更加注重那么远离中心的点.</li>
</ul>
<p>有关 <code>簇</code> 和 <code>质心</code> 术语更形象的介绍, 请参考下图:</p>
<p>![K-Means 术语图]({{ site.baseurl }}{{ site.images }}/MachineLearninginAction/10.KMeans/apachecn-k-means-term-1.jpg)</p>
<h3 id="k-means_3">K-Means 工作流程</h3>
<ol>
<li>首先, 随机确定 K 个初始点作为质心（不是数据中的点）.</li>
<li>然后将数据集中的每个点分配到一个簇中, 具体来讲, 就是为每个点找到距其最近的质心, 并将其分配该质心所对应的簇. 这一步完成之后, 每个簇的质心更新为该簇所有点的平均值.</li>
</ol>
<p>上述过程的 <code>伪代码</code> 如下:</p>
<ul>
<li>创建 k 个点作为起始质心（通常是随机选择）</li>
<li>当任意一个点的簇分配结果发生改变时<ul>
<li>对数据集中的每个数据点<ul>
<li>对每个质心<ul>
<li>计算质心与数据点之间的距离</li>
</ul>
</li>
<li>将数据点分配到距其最近的簇</li>
</ul>
</li>
<li>对每一个簇, 计算簇中所有点的均值并将均值作为质心</li>
</ul>
</li>
</ul>
<h3 id="k-means_4">K-Means 开发流程</h3>
<div class="highlight"><pre><span></span>收集数据：使用任意方法
准备数据：需要数值型数据类计算距离, 也可以将标称型数据映射为二值型数据再用于距离计算
分析数据：使用任意方法
训练算法：此步骤不适用于 K-Means 算法
测试算法：应用聚类算法、观察结果.可以使用量化的误差指标如误差平方和（后面会介绍）来评价算法的结果.
使用算法：可以用于所希望的任何应用.通常情况下, 簇质心可以代表整个簇的数据来做出决策.
</pre></div>

<h3 id="k-means_5">K-Means 聚类算法函数</h3>
<h4 id="_1">从文件加载数据集</h4>
<div class="highlight"><pre><span></span><span class="c1"># 从文本中构建矩阵，加载文本文件，然后处理</span>
<span class="k">def</span> <span class="nf">loadDataSet</span><span class="p">(</span><span class="n">fileName</span><span class="p">):</span>    <span class="c1"># 通用函数，用来解析以 tab 键分隔的 floats（浮点数），例如: 1.658985    4.285136</span>
    <span class="n">dataMat</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">fr</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">fileName</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">fr</span><span class="o">.</span><span class="n">readlines</span><span class="p">():</span>
        <span class="n">curLine</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">fltLine</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">float</span><span class="p">,</span><span class="n">curLine</span><span class="p">)</span>    <span class="c1"># 映射所有的元素为 float（浮点数）类型</span>
        <span class="n">dataMat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fltLine</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dataMat</span>
</pre></div>

<h4 id="_2">计算两个向量的欧氏距离</h4>
<div class="highlight"><pre><span></span><span class="c1"># 计算两个向量的欧式距离（可根据场景选择）</span>
<span class="k">def</span> <span class="nf">distEclud</span><span class="p">(</span><span class="n">vecA</span><span class="p">,</span> <span class="n">vecB</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">power</span><span class="p">(</span><span class="n">vecA</span> <span class="o">-</span> <span class="n">vecB</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span> <span class="c1"># la.norm(vecA-vecB)</span>
</pre></div>

<h4 id="k">构建一个包含 K 个随机质心的集合</h4>
<div class="highlight"><pre><span></span><span class="c1"># 为给定数据集构建一个包含 k 个随机质心的集合。随机质心必须要在整个数据集的边界之内，这可以通过找到数据集每一维的最小和最大值来完成。然后生成 0~1.0 之间的随机数并通过取值范围和最小值，以便确保随机点在数据的边界之内。</span>
<span class="k">def</span> <span class="nf">randCent</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">shape</span><span class="p">(</span><span class="n">dataSet</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># 列的数量</span>
    <span class="n">centroids</span> <span class="o">=</span> <span class="n">mat</span><span class="p">(</span><span class="n">zeros</span><span class="p">((</span><span class="n">k</span><span class="p">,</span><span class="n">n</span><span class="p">)))</span> <span class="c1"># 创建k个质心矩阵</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span> <span class="c1"># 创建随机簇质心，并且在每一维的边界内</span>
        <span class="n">minJ</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">dataSet</span><span class="p">[:,</span><span class="n">j</span><span class="p">])</span>    <span class="c1"># 最小值</span>
        <span class="n">rangeJ</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">dataSet</span><span class="p">[:,</span><span class="n">j</span><span class="p">])</span> <span class="o">-</span> <span class="n">minJ</span><span class="p">)</span>    <span class="c1"># 范围 = 最大值 - 最小值</span>
        <span class="n">centroids</span><span class="p">[:,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">mat</span><span class="p">(</span><span class="n">minJ</span> <span class="o">+</span> <span class="n">rangeJ</span> <span class="o">*</span> <span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>    <span class="c1"># 随机生成</span>
    <span class="k">return</span> <span class="n">centroids</span>
</pre></div>

<h4 id="k-means_6">K-Means 聚类算法</h4>
<div class="highlight"><pre><span></span><span class="c1"># k-means 聚类算法</span>
<span class="c1"># 该算法会创建k个质心，然后将每个点分配到最近的质心，再重新计算质心。</span>
<span class="c1"># 这个过程重复数次，直到数据点的簇分配结果不再改变位置。</span>
<span class="c1"># 运行结果（多次运行结果可能会不一样，可以试试，原因为随机质心的影响，但总的结果是对的， 因为数据足够相似，也可能会陷入局部最小值）</span>
<span class="k">def</span> <span class="nf">kMeans</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">distMeas</span><span class="o">=</span><span class="n">distEclud</span><span class="p">,</span> <span class="n">createCent</span><span class="o">=</span><span class="n">randCent</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">shape</span><span class="p">(</span><span class="n">dataSet</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>    <span class="c1"># 行数</span>
    <span class="n">clusterAssment</span> <span class="o">=</span> <span class="n">mat</span><span class="p">(</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>    <span class="c1"># 创建一个与 dataSet 行数一样，但是有两列的矩阵，用来保存簇分配结果</span>
    <span class="n">centroids</span> <span class="o">=</span> <span class="n">createCent</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>    <span class="c1"># 创建质心，随机k个质心</span>
    <span class="n">clusterChanged</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="k">while</span> <span class="n">clusterChanged</span><span class="p">:</span>
        <span class="n">clusterChanged</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>    <span class="c1"># 循环每一个数据点并分配到最近的质心中去</span>
            <span class="n">minDist</span> <span class="o">=</span> <span class="n">inf</span><span class="p">;</span> <span class="n">minIndex</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
                <span class="n">distJI</span> <span class="o">=</span> <span class="n">distMeas</span><span class="p">(</span><span class="n">centroids</span><span class="p">[</span><span class="n">j</span><span class="p">,:],</span><span class="n">dataSet</span><span class="p">[</span><span class="n">i</span><span class="p">,:])</span>    <span class="c1"># 计算数据点到质心的距离</span>
                <span class="k">if</span> <span class="n">distJI</span> <span class="o">&lt;</span> <span class="n">minDist</span><span class="p">:</span>    <span class="c1"># 如果距离比 minDist（最小距离）还小，更新 minDist（最小距离）和最小质心的 index（索引）</span>
                    <span class="n">minDist</span> <span class="o">=</span> <span class="n">distJI</span><span class="p">;</span> <span class="n">minIndex</span> <span class="o">=</span> <span class="n">j</span>
            <span class="k">if</span> <span class="n">clusterAssment</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">minIndex</span><span class="p">:</span>    <span class="c1"># 簇分配结果改变</span>
                <span class="n">clusterChanged</span> <span class="o">=</span> <span class="bp">True</span>    <span class="c1"># 簇改变</span>
                <span class="n">clusterAssment</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">minIndex</span><span class="p">,</span><span class="n">minDist</span><span class="o">**</span><span class="mi">2</span>    <span class="c1"># 更新簇分配结果为最小质心的 index（索引），minDist（最小距离）的平方</span>
        <span class="k">print</span> <span class="n">centroids</span>
        <span class="k">for</span> <span class="n">cent</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span> <span class="c1"># 更新质心</span>
            <span class="n">ptsInClust</span> <span class="o">=</span> <span class="n">dataSet</span><span class="p">[</span><span class="n">nonzero</span><span class="p">(</span><span class="n">clusterAssment</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">A</span><span class="o">==</span><span class="n">cent</span><span class="p">)[</span><span class="mi">0</span><span class="p">]]</span> <span class="c1"># 获取该簇中的所有点</span>
            <span class="n">centroids</span><span class="p">[</span><span class="n">cent</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">ptsInClust</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># 将质心修改为簇中所有点的平均值，mean 就是求平均值的</span>
    <span class="k">return</span> <span class="n">centroids</span><span class="p">,</span> <span class="n">clusterAssment</span>
</pre></div>

<h4 id="_3">测试函数</h4>
<ol>
<li>测试一下以上的基础函数是否可以如预期运行, 请看: <a href="https://github.com/apachecn/MachineLearning/blob/master/src/python/10.kmeans/kMeans.py">https://github.com/apachecn/MachineLearning/blob/master/src/python/10.kmeans/kMeans.py</a></li>
<li>测试一下 kMeans 函数是否可以如预期运行, 请看: <a href="https://github.com/apachecn/MachineLearning/blob/master/src/python/10.kmeans/kMeans.py">https://github.com/apachecn/MachineLearning/blob/master/src/python/10.kmeans/kMeans.py</a> </li>
</ol>
<p>参考运行结果如下:<br />
![K-Means 运行结果1]({{ site.baseurl }}{{ site.images }}/MachineLearninginAction/10.KMeans/apachecn-k-means-run-result-1.jpg)</p>
<blockquote>
<p>在 kMeans 的函数测试中，可能偶尔会陷入局部最小值（局部最优的结果，但不是全局最优的结果）.</p>
</blockquote>
<h3 id="k-means_7">K-Means 聚类算法的缺陷</h3>
<p>在 kMeans 的函数测试中，可能偶尔会陷入局部最小值（局部最优的结果，但不是全局最优的结果）. <br />
局部最小值的的情况如下:<br />
![K-Means 局部最小值1]({{ site.baseurl }}{{ site.images }}/MachineLearninginAction/10.KMeans/apachecn-kmeans-partial-best-result-1.jpg)</p>
<p>所以为了克服 KMeans 算法收敛于局部最小值的问题，有更厉害的大佬提出了另一个称之为二分K-均值（bisecting K-Means）的算法.   </p>
<h3 id="k-means_8">二分 K-Means 聚类算法</h3>
<p>该算法首先将所有点作为一个簇，然后将该簇一分为二。<br />
之后选择其中一个簇继续进行划分，选择哪一个簇进行划分取决于对其划分时候可以最大程度降低 SSE（平方和误差）的值。<br />
上述基于 SSE 的划分过程不断重复，直到得到用户指定的簇数目为止。  </p>
<h4 id="k-means_9">二分 K-Means 聚类算法伪代码</h4>
<ul>
<li>将所有点看成一个簇</li>
<li>当簇数目小雨 k 时</li>
<li>对于每一个簇<ul>
<li>计算总误差</li>
<li>在给定的簇上面进行 KMeans 聚类（k=2）</li>
<li>计算将该簇一分为二之后的总误差</li>
</ul>
</li>
<li>选择使得误差最小的那个簇进行划分操作</li>
</ul>
<p>另一种做法是选择 SSE 最大的簇进行划分，直到簇数目达到用户指定的数目位置。
接下来主要介绍该做法。</p>
<h4 id="k-means_10">二分 K-Means 聚类算法代码</h4>
<div class="highlight"><pre><span></span><span class="c1"># 二分 KMeans 聚类算法, 基于 kMeans 基础之上的优化，以避免陷入局部最小值</span>
<span class="k">def</span> <span class="nf">biKMeans</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">distMeas</span><span class="o">=</span><span class="n">distEclud</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">shape</span><span class="p">(</span><span class="n">dataSet</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">clusterAssment</span> <span class="o">=</span> <span class="n">mat</span><span class="p">(</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span> <span class="c1"># 保存每个数据点的簇分配结果和平方误差</span>
    <span class="n">centroid0</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">dataSet</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># 质心初始化为所有数据点的均值</span>
    <span class="n">centList</span> <span class="o">=</span><span class="p">[</span><span class="n">centroid0</span><span class="p">]</span> <span class="c1"># 初始化只有 1 个质心的 list</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span> <span class="c1"># 计算所有数据点到初始质心的距离平方误差</span>
        <span class="n">clusterAssment</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">distMeas</span><span class="p">(</span><span class="n">mat</span><span class="p">(</span><span class="n">centroid0</span><span class="p">),</span> <span class="n">dataSet</span><span class="p">[</span><span class="n">j</span><span class="p">,:])</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">while</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">centList</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">k</span><span class="p">):</span> <span class="c1"># 当质心数量小于 k 时</span>
        <span class="n">lowestSSE</span> <span class="o">=</span> <span class="n">inf</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">centList</span><span class="p">)):</span> <span class="c1"># 对每一个质心</span>
            <span class="n">ptsInCurrCluster</span> <span class="o">=</span> <span class="n">dataSet</span><span class="p">[</span><span class="n">nonzero</span><span class="p">(</span><span class="n">clusterAssment</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">A</span><span class="o">==</span><span class="n">i</span><span class="p">)[</span><span class="mi">0</span><span class="p">],:]</span> <span class="c1"># 获取当前簇 i 下的所有数据点</span>
            <span class="n">centroidMat</span><span class="p">,</span> <span class="n">splitClustAss</span> <span class="o">=</span> <span class="n">kMeans</span><span class="p">(</span><span class="n">ptsInCurrCluster</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">distMeas</span><span class="p">)</span> <span class="c1"># 将当前簇 i 进行二分 kMeans 处理</span>
            <span class="n">sseSplit</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">splitClustAss</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># 将二分 kMeans 结果中的平方和的距离进行求和</span>
            <span class="n">sseNotSplit</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">clusterAssment</span><span class="p">[</span><span class="n">nonzero</span><span class="p">(</span><span class="n">clusterAssment</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">A</span><span class="o">!=</span><span class="n">i</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># 将未参与二分 kMeans 分配结果中的平方和的距离进行求和</span>
            <span class="k">print</span> <span class="s2">&quot;sseSplit, and notSplit: &quot;</span><span class="p">,</span><span class="n">sseSplit</span><span class="p">,</span><span class="n">sseNotSplit</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">sseSplit</span> <span class="o">+</span> <span class="n">sseNotSplit</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">lowestSSE</span><span class="p">:</span> <span class="c1"># 总的（未拆分和已拆分）误差和越小，越相似，效果越优化，划分的结果更好（注意：这里的理解很重要，不明白的地方可以和我们一起讨论）</span>
                <span class="n">bestCentToSplit</span> <span class="o">=</span> <span class="n">i</span>
                <span class="n">bestNewCents</span> <span class="o">=</span> <span class="n">centroidMat</span>
                <span class="n">bestClustAss</span> <span class="o">=</span> <span class="n">splitClustAss</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">lowestSSE</span> <span class="o">=</span> <span class="n">sseSplit</span> <span class="o">+</span> <span class="n">sseNotSplit</span>
        <span class="c1"># 找出最好的簇分配结果    </span>
        <span class="n">bestClustAss</span><span class="p">[</span><span class="n">nonzero</span><span class="p">(</span><span class="n">bestClustAss</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">A</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">centList</span><span class="p">)</span> <span class="c1"># 调用二分 kMeans 的结果，默认簇是 0,1. 当然也可以改成其它的数字</span>
        <span class="n">bestClustAss</span><span class="p">[</span><span class="n">nonzero</span><span class="p">(</span><span class="n">bestClustAss</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">A</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">bestCentToSplit</span> <span class="c1"># 更新为最佳质心</span>
        <span class="k">print</span> <span class="s1">&#39;the bestCentToSplit is: &#39;</span><span class="p">,</span><span class="n">bestCentToSplit</span>
        <span class="k">print</span> <span class="s1">&#39;the len of bestClustAss is: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">bestClustAss</span><span class="p">)</span>
        <span class="c1"># 更新质心列表</span>
        <span class="n">centList</span><span class="p">[</span><span class="n">bestCentToSplit</span><span class="p">]</span> <span class="o">=</span> <span class="n">bestNewCents</span><span class="p">[</span><span class="mi">0</span><span class="p">,:]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># 更新原质心 list 中的第 i 个质心为使用二分 kMeans 后 bestNewCents 的第一个质心</span>
        <span class="n">centList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bestNewCents</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># 添加 bestNewCents 的第二个质心</span>
        <span class="n">clusterAssment</span><span class="p">[</span><span class="n">nonzero</span><span class="p">(</span><span class="n">clusterAssment</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">A</span> <span class="o">==</span> <span class="n">bestCentToSplit</span><span class="p">)[</span><span class="mi">0</span><span class="p">],:]</span><span class="o">=</span> <span class="n">bestClustAss</span> <span class="c1"># 重新分配最好簇下的数据（质心）以及SSE</span>
    <span class="k">return</span> <span class="n">mat</span><span class="p">(</span><span class="n">centList</span><span class="p">),</span> <span class="n">clusterAssment</span>
</pre></div>

<h4 id="kmeans">测试二分 KMeans 聚类算法</h4>
<ul>
<li>测试一下二分 KMeans 聚类算法，请看: <a href="https://github.com/apachecn/MachineLearning/blob/master/src/python/10.kmeans/kMeans.py">https://github.com/apachecn/MachineLearning/blob/master/src/python/10.kmeans/kMeans.py</a></li>
</ul>
<p>上述函数可以运行多次，聚类会收敛到全局最小值，而原始的 kMeans() 函数偶尔会陷入局部最小值。<br />
运行参考结果如下:<br />
![二分 K-Means 运行结果1]({{ site.baseurl }}{{ site.images }}/MachineLearninginAction/10.KMeans/apachecn-bikmeans-run-result-1.jpg)</p>
<ul>
<li><strong>作者：<a href="http://www.apache.wiki/display/~xuxin">那伊抹微笑</a></strong></li>
<li><a href="https://github.com/apachecn/MachineLearning">GitHub地址</a>: <a href="https://github.com/apachecn/MachineLearning">https://github.com/apachecn/MachineLearning</a></li>
<li><strong>版权声明：欢迎转载学习 =&gt; 请标注信息来源于 <a href="http://www.apachecn.org/">ApacheCN</a></strong></li>
</ul></div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>var base_url = '../..';</script>
        <script src="../../js/base.js"></script>
        <script src="../../javascripts/extra.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        <script src="../../search/require.js"></script>
        <script src="../../search/search.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="Keyboard Shortcuts Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Keyboard Shortcuts</h4>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td><kbd>&larr;</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td><kbd>&rarr;</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>


    </body>
</html>
